一、解决业务需求应该具备的能力

1. 熟悉模型

（1）模型能力摸底
知道模型有哪些能力项分类，知道各能力项的大致数据分布，知道各个能力项的能力上限是什么。

（2）熟悉模型的默认输出倾向
比如知识问答倾向于输出短答案还是长答案，文案创作倾向于正经话术还是幽默风格。

（3）熟悉模型的指令遵从程度
包括不限于意图识别、复杂指令理解、复杂输出格式遵从等。

（4）了解模型能力短板
知道模型暂时无法解决的问题是什么。比如幻觉问题、准确性问题、数学计算正确性问题、创作细节性问题、创作自然性问题。这些问题有的是模型能力/训练的问题，有的是模型训练数据的问题。

2. 优化模型原始输出
   
（1）输出问题定位
遇到不符合预期的输出大概能判断出问题点在哪里，包括不限于基础能力的缺失、指令前后矛盾/不明确、任务定位错误等。

（2）最大化激发模型的单项能力
不同场景和任务调优prompt的技巧不同，样例法比较适合于情景可枚举、任务不过于复杂的场景，在设定样例的时候需要做到尽可能覆盖全部情况加全部可能输出的排列组合；详细要求的方法比较适合于输出有明显要点或者表征，比如语言风格、违禁词、推荐词、格式等。

（3）充分利用模型的综合能力
有时候一项任务的输出不一定只通过一次QA可以得到最优解，比如可以经过多轮总结改写、先获取信息再基于信息创作等，可以综合利用模型的多项能力完成某个场景的最优输出。

3. 端到端解决方案
   
（1）业务逻辑拆解
将业务逻辑进行拆分，正确地对应到大模型对应的各个能力项上，看怎么搭配组合能够更好地实现需求。同时对业务需求，尤其是相对于大模型而言是从未见过的业务场景，则需要研发人员充分理解业务逻辑链的具体细节，从而去“教”大模型这一套逻辑。

（2）知道这个场景prompt是否能解决
如果大模型的推理逻辑足够强，那么在一个大概有三四个子步骤的新场景时，通过思维链的细致描述是可以让模型理解这个任务并得到较好的输出的；
如果大模型逻辑推理能力没那么强，可以分三四个子步骤多次单点调用，用模型的组合能力来实现需求；
如果二者都不可行，则需要进行微调。

（3）知道怎么微调
首先需要判断模型对业务场景的表现不理想是行业领域知识的缺失/指令的不理解/输出准确性不高。
如果是前者则可以配合一些带有行业知识的其他任务混合进行训练；
如果是指令不理解，则需要判断是否基模型对复杂指令理解遵从性就不强，是的话需要进行基模型的优化，如果不是则使用领域任务数据微调即可；
如果是输出准确性不高，一方面可以在输入prompt中详细要求输出内容风格等，且这种情况一般不微调直接用prompt（2）去激发模型能力是达不到客户期望的准确率的，建议直接走微调。

（4）知道怎么构建微调数据
有三种情况：客户有领域任务数据/客户有领域其他数据/客户没有数据。
情况1：一般来说几百条数据微调就有效果，需要把握数据的多样性：长度、情景、风格多样性等。
情况2：可以用已有大模型，结合已有领域信息数据，通过复杂prompt生成一些期望输出的数据，然后通过自动化脚本/人工检查/大模型检查等方式过滤出高质量的数据。
数据质量检查包括不限于：指令遵从性/主题一致性/格式一致性/是否有备注等多余信息/语言一致性/长度/翻译腔等。
可以使用的自动化处理方式包括不限于：实体识别的算法进行实体一致性判断/分词进行指令泛化性的判断/传统NLP分类模型/正则规则过滤等。使用大模型打分的话可以使用加分制，满足xx加一分不满足扣一分，需要详细说清所有的规则，建议让大模型输出中间分析过程，而不是直接给个分数。
情况3：其他领域类似任务公开数据的场景迁移；从0生成业务领域任务数据。后者可以从角色、情境、风格等多方面进行泛化。

（5）知道怎么挖掘潜在数据
有时候客户拥有一些领域非本任务的其他数据，他们可能觉得没用就没提，但可能对我们是有用的。
或者客户提出了个任务，但是他们的内在需求实际上用另一个任务/能力项去实现可能更能满足他们的需要，这是就要充分与客户沟通，站在客户角度去看他们想解决什么问题，然后去对应到我们的方案和能力上。

（6）端到端流程
需要领域知识或者要求高准确性和事实性的任务，往往会借助RAG的方案，这就可能涉及到检索准确率和知识库的构建，而且整个端到端方案可能涉及时延、并发等问题。

（7）借助脚本优化输出
比如模型先输出分析过程再输出结论会更准确，那么可以在内部一起输出分析和结论，经过后处理脚本呈现给客户单纯的结论。
可以使用投票打分选取最优输出。
可以结合一些可视化工具，优化模型输出的可读性和用户友好性。
可以自己猜想一些可能对客户有用的其他输出给客户做参考。（但这种情况也要进行把控，防止客户过多加需求。）

4. 常见问题和解决方案
   
（1）通用能力遗忘

（2）领域任务干扰

（3）全景数据泛化

（4）特殊数据生成
